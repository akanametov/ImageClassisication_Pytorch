{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Путешествие по Спрингфилду.\n",
    "\n",
    "\n",
    "Сегодня вам предстоить помочь телекомпании FOX  в обработке их контента. Как вы знаете сериал Симсоны идет на телеэкранах более 25 лет и за это время скопилось очень много видео материала. Персоонажи менялись вместе с изменяющимися графическими технологиями   и Гомер 2018 не очень похож на Гомера 1989. Нашей задачей будет научиться классифицировать персонажей проживающих в Спрингфилде. Думаю, что нет смысла представлять каждого из них в отдельности.\n",
    "\n",
    "\n",
    "\n",
    " ![alt text](https://vignette.wikia.nocookie.net/simpsons/images/5/5a/Spider_fat_piglet.png/revision/latest/scale-to-width-down/640?cb=20111118140828)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импортирование нужных библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка файлов\n",
    "\n",
    "Создадим функцию для загрузки файлов, который будет разделять файлы `train` на `train` и `val` и возвращать файлы для тренировки, валидации, теста и классы (42 штуки). Путем проб и ошибок становится понятно что `val_split` в 0.1 наиболее оптимален."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(train_dir, test_dir, val_size=0.1):\n",
    "\n",
    "    classes = sorted(os.listdir(train_dir))\n",
    "    test_files = sorted(Path(test_dir).rglob('*.jpg'))\n",
    "    train_val_files=sorted(Path(train_dir).rglob('*.jpg'))\n",
    "            \n",
    "    train_val_labels=[classes.index(path.parent.name) for path in train_val_files]\n",
    "    train_files, val_files = train_test_split(train_val_files, test_size=val_size,\n",
    "                                stratify=train_val_labels, random_state=42)\n",
    "    return train_files, val_files, test_files, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_dir = '../input/journey-springfield/train/simpsons_dataset/'\n",
    "test_dir = '../input/journey-springfield/testset/testset/'\n",
    "\n",
    "train_files, val_files, test_files, classes = load_files(train_dir, test_dir)\n",
    "\n",
    "train_labels = [classes.index(path.parent.name) for path in train_files]\n",
    "val_labels = [classes.index(path.parent.name) for path in val_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание датасета:\n",
    "\n",
    "При создании датасета учитываем что при `mode=='test'` метки возвращать не нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "\n",
    "    def __init__(self, files, labels=None, transform=None, mode=None):\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.mode=mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.files[idx])\n",
    "        image = self.transform(image)\n",
    "        if self.mode == 'test':\n",
    "            return image\n",
    "        else:\n",
    "            return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определение трансформов для каждого сета:\n",
    "\n",
    "При работе с различными вариантами трасформов, оказалось наиболее оптимальным решением использование только `RandomHorizontalFlip` (ну и ряда довольно дефолтных `Resize`, `Notmalize` и т.д.). Если быстро пробежаться по картинкам можно заметить, что почти во всех персонажи расположены под прямым углом и по центру. И дествительно использование `RandomResizedCrop`, `RandomAffine`, `ColorJitter` и т.д. лучших значении на тестовой выборке не дало при этом сходимость наблюдалась на более поздних эпохах. В силу нецелесообразности вышеупомянутых трансформов был использован только `RandomHorizontalFlip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(224, 224)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataSet(train_files, train_labels, train_transforms, 'train')\n",
    "val_set = DataSet(val_files, val_labels, val_transforms, 'val')\n",
    "test_set = DataSet(test_files, None, test_transforms, 'test')\n",
    "\n",
    "print('Num samples in:\\nTrain: {}\\nVal: {}\\nTest: {}'.format(len(train_set), len(val_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробовав различные `batch_size` пришел к выводу что `batch_size=32` является наиболее подходящим.(Для наилучшей воспроизводимости ставим `shuffle=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataLoader(train_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "val_gen = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_gen = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print('Num batches in:\\nTrain: {}\\nVal: {}\\nTest: {}'.format(len(train_gen), len(val_gen), len(test_gen)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение модели\n",
    "\n",
    "Мы будем использовать предобученный ResNet152. Замораживать слои мы не будем. И изменим только классификатор (последний FC слои) на такой же послносвязный только с нужным количеством классов на выходе. (Можно попробовать и ResNet18, который наиболее прост и потребляет не столько ресурсов как ResNet152. **Однако несмотря на то что ResNet152 обучается ~ 4 минуты/эпоху, а ResNet18 ~ 2 минуты/эпоху, ResNet152 дает больший скор за 5 эпох чем ResNet18 за 10. За одну эпоху ResNet152 дает ~ 0.81 на трейне и ~ 0.97 на валидации, что довольно впечетляюще.)**\n",
    "\n",
    "**ОБУЧЕННУЮ МОДЕЛЬ МОЖНО НАЙТИ ПО ССЫЛКЕ:** [simpsons_resnet152.pth](https://www.kaggle.com/kanametov/add-to-simpsons#best_model_resnet152_v1.pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet152(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad == True\n",
    "    \n",
    "model.fc = nn.Linear(2048, 42)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение весов\n",
    "\n",
    "Поскольку некоторые классы имеют большее значение для данной задачи мы определим веса для каждого из классов. Все классы в которых имеется больше 200 сэмплов (картинок) в датасете будем причислять к **важным классам**. Для них веса будут больше. Вес класса входящего в список **важных** будет обратно зависеть от количества сэмплов в нем. Т.о. мы как бы выравниваем количество сэмплов в каждом из **важных классов** штрафуя больше те в котрых меньше картинок.\n",
    "\n",
    "**ВЕСА МОЖНО НАЙТИ ПО ССЫЛКЕ:** [weights.csv](https://www.kaggle.com/kanametov/add-to-simpsons#final_weights(not_uniform).csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights(train_dir, classes):\n",
    "    files = sorted(Path(train_dir).rglob('*.jpg'))\n",
    "    important_classes=[]\n",
    "    important_samples=[]\n",
    "    num_samples_per_class={}\n",
    "    for cls in classes:\n",
    "        num_samples = len(sorted(Path(os.path.join(train_dir, cls)).rglob('*.jpg')))\n",
    "        num_samples_per_class[cls] = num_samples\n",
    "        if num_samples>200:\n",
    "            important_classes.append(cls)\n",
    "            important_samples.append(num_samples)\n",
    "\n",
    "    weights=[]\n",
    "    for cls in classes:\n",
    "        if cls in important_classes:\n",
    "            w = 0.05*(sum(important_samples)/(len(important_classes)*num_samples_per_class[cls]))\n",
    "            weights.append(w)\n",
    "        else:\n",
    "            w = 0.5*(num_samples_per_class[cls]/sum(num_samples_per_class.values()))\n",
    "            weights.append(w)\n",
    "    norm_weights = [w/sum(weights) for w in weights]\n",
    "    return norm_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=generate_weights(train_dir, classes)\n",
    "weights = torch.FloatTensor(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение функции потерь и оптимизатора\n",
    "\n",
    "Попробовав различные оптимизаторы (`Adam`, `Adam + amsgrad`, `RMSProp`, `SGD`) пришел к выводу что `SGD` c циклическим `learning_rate` наиболее оптимален .(Параметры подобраны методом проб и ошибок. Для каждой модели стоит поискать наиболее подходящие)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.0018\n",
    "max_lr = 0.0032\n",
    "batch_size=32\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weights).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov = True)\n",
    "step_size = 2 * math.ceil(len(train_set)/batch_size)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr = base_lr, max_lr = max_lr,\n",
    "                                              step_size_up=step_size, mode='exp_range', gamma=0.994,\n",
    "                                              scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение функции тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_gen, val_gen, epochs=5):\n",
    "    val_acc = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, epochs))\n",
    "        print('-' * 10)\n",
    "        model.train()  \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in tqdm(train_gen):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(train_gen.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_gen.dataset)\n",
    "        train_acc.append(epoch_acc)\n",
    "        train_loss.append(epoch_loss)\n",
    "        \n",
    "        print('Train loss: {:.4f} --- Train accuracy: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        model.eval()  \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in tqdm(val_gen):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(val_gen.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(val_gen.dataset)\n",
    "        val_acc.append(epoch_acc)\n",
    "        val_loss.append(epoch_loss)\n",
    "        print('Validation loss: {:.4f} --- Validation accuracy: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "    return {'loss': train_loss, 'acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренировка модели\n",
    "\n",
    "**ОБУЧЕННУЮ МОДЕЛЬ МОЖНО НАЙТИ ПО ССЫЛКЕ:** [simpsons_resnet152.pth](https://www.kaggle.com/kanametov/add-to-simpsons#best_model_resnet152_v1.pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(train_gen, val_gen, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также дообучить классификатор модели используя следующий код:\n",
    "```python\n",
    "for param in model.parameters():\n",
    "    param.requires_grad == False\n",
    "    \n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad == True\n",
    "```\n",
    "Однако это не дало лучшего скора, поэтому пользоваться этим подходом для данной модели мы не будем. (В ином случае стоит попробовать)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохранение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_model_resnet152_v1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history['loss']\n",
    "acc = history['acc']\n",
    "val_loss = history['val_loss']\n",
    "val_acc = history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(loss)+1), loss, 'r-', label='train')\n",
    "plt.plot(range(1, len(val_loss)+1), val_loss, 'b-', label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(acc)+1), acc, 'r-', label='train')\n",
    "plt.plot(range(1, len(val_acc)+1), val_acc, 'b-', label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на тестовых данных\n",
    "\n",
    "#### Функция предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_gen):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "    \n",
    "        for inputs in test_gen:\n",
    "            inputs = inputs.to(device)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = predict(test_gen)\n",
    "test_labels = np.argmax(probs, axis=1)\n",
    "test_classes = [classes[i] for i in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submit = pd.DataFrame({'Id': sorted(os.listdir(test_dir)), 'Expected': test_classes})\n",
    "my_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submit.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
